{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56530c90",
   "metadata": {},
   "source": [
    "# 2. 넘파이로 텐서 만들기(벡터와 행렬 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c825ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deebce1",
   "metadata": {},
   "source": [
    "### 1) 1D with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57a8ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "# 1차원 벡터 만들기\n",
    "t = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "# List를 생성해서 np.array로 1차원 array로 변환함\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da389b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of t:  1\n",
      "Shape of t:  (7,)\n"
     ]
    }
   ],
   "source": [
    "# 1차원 벡터의 차원과 크기\n",
    "print('Rank of t: ', t.ndim)\n",
    "print('Shape of t: ', t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979c6ee",
   "metadata": {},
   "source": [
    "### 2) 2D with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3f62d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "# 2차원 행렬 만들기\n",
    "t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8857ab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank  of t:  2\n",
      "Shape of t:  (4, 3)\n"
     ]
    }
   ],
   "source": [
    "# 2차원 행렬의 차원과 크기\n",
    "print('Rank  of t: ', t.ndim)\n",
    "print('Shape of t: ', t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd198669",
   "metadata": {},
   "source": [
    "# 3. 파이토치 텐서 선언하기(PyTorch Tensor Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a065f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39231f",
   "metadata": {},
   "source": [
    "### 1) 1D with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a47f44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# 1차원 벡터 만들기\n",
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad25170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "# 1차원 벡터의 차원과 크기\n",
    "print(t.dim())  # rank. 즉, 차원\n",
    "print(t.shape)  # shape\n",
    "print(t.size()) # shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4df9a7",
   "metadata": {},
   "source": [
    "### 2) 2D with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25253eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# 2차원 행렬 만들기\n",
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                       [4., 5., 6.],\n",
    "                       [7., 8., 9.],\n",
    "                       [10., 11., 12.]\n",
    "                      ])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03e47428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2차원 행렬의 차원과 크기\n",
    "print(t.dim())  # rank. 즉, 차원\n",
    "print(t.size()) # shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a97c96",
   "metadata": {},
   "source": [
    "### 3) 브로드캐스팅(Broadcasting)\n",
    "딥러닝을 하게되면 불가피하게 크기가 다른 행렬 또는 텐서에 대해서 사칙 연산을 수행할 필요가 있는 경우가 생김.  \n",
    "이를 위해 PyTorch에서는 자동으로 크기를 맞춰서 연산을 수행하게 만드는 **브로드캐스팅**이라는 기능을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb0871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([3]) # [3] -> [3, 3]\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5989f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]]) # [1, 2] -> [[1, 2], [1, 2]]\n",
    "m2 = torch.FloatTensor([[3], [4]]) # [[3],[4]] -> [[3, 3],[4, 4]]\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c18d0",
   "metadata": {},
   "source": [
    "> 브로드캐스팅은 편리하지만, 자동으로 실행되는 기능이므로 사용자 입장에서 굉장히 주의해서 사용  \n",
    "\n",
    "> 만약, 두 텐서의 크기가 다르다고 에러를 발생시킨다면 사용자는 이 연산이 잘못되었음을 바로 알 수 있지만 브로드캐스팅은 자동으로 수행되므로 사용자는 나중에 원하는 결과가 나오지 않았더라도 어디서 문제가 발생했는지 찾기가 굉장히 어려울 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b615a0b",
   "metadata": {},
   "source": [
    "### 4) 자주 사용되는 기능들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b24eb",
   "metadata": {},
   "source": [
    "- **행렬 곱셈과 곱셈의 차이(Matrix Multiplication Vs. Multiplication)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ed0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬 곱셈\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1.matmul(m2)) # 2 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e4a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# 원소별 곱셈\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]]) # [[1], [2]] -> [[1, 1], [2, 2]]\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1 * m2) # 2 x 2\n",
    "# print(m1.mul(m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91323c31",
   "metadata": {},
   "source": [
    "- **평균(Mean)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b13d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "# 1차원\n",
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f067e8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "# 2차원\n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t.mean())\n",
    "# 차원을 인자로 주는 경우(해당 차원을 제거한다는 의미)\n",
    "print(t.mean(dim=0)) # 행의 차원 제거\n",
    "print(t.mean(dim=1)) # 열의 차원 제거\n",
    "print(t.mean(dim=-1)) # 마지막 차원 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d548b11",
   "metadata": {},
   "source": [
    "- **덧셈(Sum)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbb3683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t.sum()) # 단순히 원소 전체의 덧셈을 수행\n",
    "print(t.sum(dim=0)) # 행을 제거\n",
    "print(t.sum(dim=1)) # 열을 제거\n",
    "print(t.sum(dim=-1)) # 열을 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e695215",
   "metadata": {},
   "source": [
    "- **최대(Max)와 아그맥스(ArgMax)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf2140da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t.max()) # Returns one value: max\n",
    "print(t.max(dim=0)) # Returns two values: max and argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f3c7e",
   "metadata": {},
   "source": [
    "> max에 dim 인자를 주면 argmax도 함께 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1d46356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max:  tensor([3., 4.])\n",
      "Argmax:  tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# max 또는 argmax만 리턴받고 싶다면\n",
    "print('Max: ', t.max(dim=0)[0])\n",
    "print('Argmax: ', t.max(dim=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26efe9",
   "metadata": {},
   "source": [
    "- **뷰(View)** - 원소의 수를 유지하면서 텐서의 크기 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46311559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "\n",
      "<3차원 텐서에서 2차원 텐서로 변경>\n",
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n",
      "\n",
      "<3차원 텐서의 크기 변경>\n",
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 텐서의 뷰(View)는 Numpy에서의 리쉐이프(Reshape)와 같은 역할\n",
    "t = np.array([[[0, 1, 2],\n",
    "               [3, 4, 5]],\n",
    "              [[6, 7, 8],\n",
    "               [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.shape)\n",
    "\n",
    "print(\"\\n<3차원 텐서에서 2차원 텐서로 변경>\")\n",
    "print(ft.view([-1, 3])) # ft라는 텐서를 (?, 3)의 크기로 변경\n",
    "print(ft.view([-1, 3]).shape)\n",
    "\n",
    "print(\"\\n<3차원 텐서의 크기 변경>\")\n",
    "print(ft.view([-1, 1, 3]))\n",
    "print(ft.view([-1, 1, 3]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8aef8a",
   "metadata": {},
   "source": [
    "- **스퀴즈(Squeeze)** - 1인 차원을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56afed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<두번째 차원이 1이므로 squeeze를 사용>\n",
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.FloatTensor([[0], [1], [2]])\n",
    "print(ft)\n",
    "print(ft.shape)\n",
    "\n",
    "print(\"\\n<두번째 차원이 1이므로 squeeze를 사용>\")\n",
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb996c",
   "metadata": {},
   "source": [
    "- **언스퀴즈(Unsqueeze)** - 특정 위치에 1인 차원을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b3a188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "\n",
      "<첫번째 차원에 1인 차원을 추가>\n",
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.Tensor([0, 1, 2])\n",
    "print(ft.shape)\n",
    "\n",
    "print(\"\\n<첫번째 차원에 1인 차원을 추가>\")\n",
    "print(ft.unsqueeze(0)) # 인덱스가 0부터 시작하므로 0은 첫번째 차원을 의미한다.\n",
    "print(ft.unsqueeze(0).shape)\n",
    "# == print(ft.view(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f742f",
   "metadata": {},
   "source": [
    "- **타입 캐스팅(Type Casting)**\n",
    "  \n",
    "![Type Casting](./data/Type_Casting.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc197c4f",
   "metadata": {},
   "source": [
    "> 텐서에는 자료형이라는 것이 있음.  \n",
    "> 각 데이터형별로 정의되어져 있는데, 예를 들어 32비트의 유동 소수점은 torch.FloatTensor를, 64비트의 부호 있는 정수는 torch.LongTensor를 사용.  \n",
    "> GPU 연산을 위한 자료형도 있음 (ex. torch.cuda.FloatTensor)\n",
    "\n",
    ">> 이 자료형을 변환하는 것을 타입 캐스팅이라고 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e5e015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "# long 타입의 lt라는 텐서를 선언\n",
    "lt = torch.LongTensor([1, 2, 3, 4])\n",
    "print(lt)\n",
    "print(lt.float()) # 텐서에다가 .float()를 붙이면 바로 float형으로 타입이 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "050635ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([1., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Byte 타입의 bt라는 텐서를 선언\n",
    "bt = torch.ByteTensor([True, False, False, True])\n",
    "print(bt)\n",
    "print(bt.long()) # .long()이라고하면 long 타입의 텐서로 변경\n",
    "print(bt.float()) # .float()이라고 하면 float 타입의 텐서로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c93185d",
   "metadata": {},
   "source": [
    "- **연결하기(concatenate)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9ed1d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "y = torch.FloatTensor([[5, 6], [7, 8]])\n",
    "# 어느 차원을 늘릴 것인지를 인자로 줄 수 있음.\n",
    "print(torch.cat([x, y], dim=0)) # (2 X 2) -> (4 X 2)\n",
    "print(torch.cat([x, y], dim=1)) # (2 X 2) -> (2 X 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb6ecf",
   "metadata": {},
   "source": [
    "- **스택킹(Stacking)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a88861a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1, 4])\n",
    "y = torch.FloatTensor([2, 5])\n",
    "z = torch.FloatTensor([3, 6])\n",
    "print(torch.stack([x, y, z]))\n",
    "# == print(torch.cat([x.unsqueeze(0), y.unsqueeze(0), z.unsqueeze(0)], dim=0))\n",
    "print(torch.stack([x, y, z], dim=1)) # 두번째 차원이 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e82e43",
   "metadata": {},
   "source": [
    "- **ones_like와 zeros_like** - 0으로 채워진 텐서와 1로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4606076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])\n",
    "print(x)\n",
    "print(torch.ones_like(x)) # 입력 텐서와 크기를 동일하게 하면서 값을 1로 채우기\n",
    "print(torch.zeros_like(x)) # 입력 텐서와 크기를 동일하게 하면서 값을 0으로 채우기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e351b",
   "metadata": {},
   "source": [
    "- **In-place Operation** - 덮어쓰기 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd8b3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "\n",
      "<'_'를 붙이면 기존의 값을 덮어씀>\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(x.mul(2.)) # 곱하기 2를 수행한 결과를 출력\n",
    "print(x) # 기존의 값 출력\n",
    "\n",
    "print(\"\\n<'_'를 붙이면 기존의 값을 덮어씀>\")\n",
    "print(x.mul_(2.))  # 곱하기 2를 수행한 결과를 변수 x에 값을 저장하면서 결과를 출력\n",
    "print(x) # 기존의 값 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DH",
   "language": "python",
   "name": "dh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
